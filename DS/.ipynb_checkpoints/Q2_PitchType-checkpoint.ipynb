{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "administrative-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 157.5 MB 95 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from xgboost) (1.6.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "western-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cellular-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitch = pd.read_csv(\"Q2_pitches_train.csv\")\n",
    "df_pitch_submit = pd.read_csv(\"Q2_pitches_test.csv\")\n",
    "#Data load and preprocessing\n",
    "#df_pitch.columns\n",
    "#Replacing bat_score_before and Field_score because they are correlated with inning with RunDiff (differential)\n",
    "#Used seaborn heatmap to check the multicollinearity, even though understanding of innings is not really numeric\n",
    "#correlations = df_pitch.loc[:,~df_pitch.columns.isin(['pitch_type','batterid','pitcherid','cid'])].corr()\n",
    "#sns.heatmap(correlations)\n",
    "df_pitch['RunDiff'] = df_pitch['field_score'] - df_pitch['bat_score_before']\n",
    "del df_pitch['bat_score_before']\n",
    "del df_pitch['field_score']\n",
    "df_pitch_submit['RunDiff'] = df_pitch_submit['field_score'] - df_pitch_submit['bat_score_before']\n",
    "del df_pitch_submit['bat_score_before']\n",
    "del df_pitch_submit['field_score'] \n",
    "del df_pitch_submit['FF'] \n",
    "del df_pitch_submit['FT'] \n",
    "del df_pitch_submit['CB'] \n",
    "del df_pitch_submit['SL'] \n",
    "del df_pitch_submit['CH'] \n",
    "#Setting up for RandomizedSearchCV to fine tune the XgBoost on the entire train dataset\n",
    "X= df_pitch.loc[:,~df_pitch.columns.isin(['pitch_type'])]\n",
    "y= df_pitch[\"pitch_type\"] \n",
    "\n",
    "X_submit = df_pitch_submit.loc[:,~df_pitch_submit.columns.isin(['pitch_type'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "handy-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_full = XGBClassifier()\n",
    "#parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    " #              \"max_depth\": [4, 6,8,10],\n",
    "  #             \"min_child_weight\": [5, 10, 15, 20],\n",
    "   #            \"n_estimators\": [100, 250, 500]}\n",
    "#We could use other parameters as well, but even this ran for some time on my laptop\n",
    "#xgb_rscv = RandomizedSearchCV(model_full, param_distributions = parameters, scoring = \"f1_micro\",\n",
    "                            # cv = 3, verbose = 3, random_state = 40 )\n",
    "#model_xgboost = xgb_rscv.fit(X, y)\n",
    "#Printing the best parameters\n",
    "#print(\"Learning Rate: \", model_xgboost.best_estimator_.get_params()[\"learning_rate\"])\n",
    "#print(\"Max Depth: \", model_xgboost.best_estimator_.get_params()[\"max_depth\"])\n",
    "#print(\"min_child_weight: \",model_xgboost.best_estimator_.get_params()[\"min_child_weight\"])\n",
    "#print(\"n_estimators: \", model_xgboost.best_estimator_.get_params()[\"n_estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "heated-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:09:23] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=15, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using these parameters to check the accuracy and classification using train and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)\n",
    "#create xgb instance with the best parameters\n",
    "clf = XGBClassifier(learning_rate=0.1,max_depth=10,min_child_weight=15,n_estimators=250, objective= 'multi:softprob')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "liquid-speed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CB       0.45      0.18      0.26     12080\n",
      "          CH       0.44      0.24      0.31     14513\n",
      "          FF       0.55      0.79      0.65     48237\n",
      "          FT       0.56      0.53      0.54     21662\n",
      "          SL       0.48      0.37      0.42     23737\n",
      "\n",
      "    accuracy                           0.53    120229\n",
      "   macro avg       0.50      0.42      0.43    120229\n",
      "weighted avg       0.51      0.53      0.50    120229\n",
      "\n",
      "['CB' 'CH' 'FF' 'FT' 'SL']\n",
      "              CB        CH        FF        FT        SL\n",
      "0       0.182459  0.043407  0.195112  0.250680  0.328343\n",
      "1       0.016524  0.068341  0.181756  0.546381  0.186998\n",
      "2       0.004794  0.018477  0.887169  0.043855  0.045705\n",
      "3       0.248402  0.109761  0.217486  0.309546  0.114805\n",
      "4       0.128486  0.013774  0.593309  0.200659  0.063772\n",
      "...          ...       ...       ...       ...       ...\n",
      "120224  0.041667  0.045187  0.413044  0.242647  0.257455\n",
      "120225  0.073791  0.472989  0.365116  0.031018  0.057087\n",
      "120226  0.252714  0.007143  0.532321  0.163462  0.044360\n",
      "120227  0.015063  0.109447  0.594317  0.029769  0.251404\n",
      "120228  0.162942  0.365243  0.369370  0.089041  0.013403\n",
      "\n",
      "[120229 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set to check accuracy and other metrics\n",
    "val_preds = clf.predict(X_test)\n",
    "prob_p= clf.predict_proba(X_test)\n",
    "#run classification report to see the total precision, recall and f1-score\n",
    "class_report = classification_report(y_test, val_preds)\n",
    "print(class_report)\n",
    "print(clf.classes_)\n",
    "#Use above classes to convert the probability matrix to dataframe\n",
    "pred_df_prob=pd.DataFrame(data=prob_p[:,:], columns=['CB', 'CH', 'FF', 'FT', 'SL'])\n",
    "print(pred_df_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dangerous-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:15:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=15, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the same model for the entire training dataset and then predict on the test set which is the submission\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "incomplete-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CB' 'CH' 'FF' 'FT' 'SL']\n",
      "              CB        CH        FF        FT        SL\n",
      "0       0.001054  0.009531  0.798821  0.132513  0.058082\n",
      "1       0.002250  0.082494  0.171777  0.033153  0.710326\n",
      "2       0.001685  0.041127  0.401256  0.046130  0.509803\n",
      "3       0.003688  0.053667  0.438138  0.025201  0.479306\n",
      "4       0.004332  0.036696  0.522732  0.020081  0.416160\n",
      "...          ...       ...       ...       ...       ...\n",
      "160301  0.159269  0.172834  0.582920  0.037037  0.047940\n",
      "160302  0.193258  0.038255  0.559172  0.086524  0.122791\n",
      "160303  0.061501  0.061146  0.786870  0.054594  0.035888\n",
      "160304  0.061501  0.061146  0.786870  0.054594  0.035888\n",
      "160305  0.061501  0.061146  0.786870  0.054594  0.035888\n",
      "\n",
      "[160306 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the final test set to give out the probabilities for each pitch to submit.\n",
    "submit_preds = clf.predict(X_submit)\n",
    "submit_prob_p= clf.predict_proba(X_submit)\n",
    "#run classification report to see the total precision, recall and f1-score\n",
    "print(clf.classes_)\n",
    "#Use above classes to convert the probability matrix to dataframe\n",
    "pred_submit_prob=pd.DataFrame(data=submit_prob_p[:,:], columns=['CB', 'CH', 'FF', 'FT', 'SL'])\n",
    "print(pred_submit_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "verbal-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the probability with the previous data.\n",
    "df_pitch_submit_data=df_pitch_submit.merge(pred_submit_prob, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fallen-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "df_pitch_submit_data.to_csv(\"Q2_pitches_test_probabilities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-amount",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
